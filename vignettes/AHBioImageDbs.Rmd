---
title: "Provide Bio-image Dataset for AnnotationHub"
author: 
- name: Satoshi Kume
  affiliation: 
    - RIKEN Center for Biosystems Dynamics Research
    - Osaka City University Center for Health Science Innovation
    - Osaka Electro-Communication University
  email: satoshi.kume.1984@gmail.com
- name: Kozo Nishida
  affiliation: RIKEN Center for Biosystems Dynamics Research
date: "`r Sys.Date()`"
graphics: no
package: AHBioImageDbs, knitr
output:
    BiocStyle::html_document:
        toc_float: true
vignette: >
    %\VignetteIndexEntry{Provide Bio-image Dataset for AnnotationHub}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
    %\VignetteDepends{AnnotationHub}
---

```{r style, echo = FALSE, results = 'asis', message=FALSE}
BiocStyle::markdown()
```

**Last modified:** `r file.info("AHBioImageDbs.Rmd")$mtime`<br />
**Compiled**: `r date()`

# Utilization and Prospects for Bioimage Datasets

In recent years, there has been a growing need for data analysis using machine 
learning in the field of biological imaging. 
Machine learning is an inductive approach using data, and the construction of 
models involves the use of image data itself.
Thus, the publication and sharing of bioimage datasets [1], as well as 
knowledge creation by adding metadata to bioimages [2, 3], are important 
issues to be discussed.
Currently, there is still no commonly-used format for publishing bioimage 
datasets. Therefore, different image repositories manage the data in different 
formats (image data itself, and metadata including image format, 
instruments/microscopes, etc.).

In data analysis using those images, it is assumed that several steps of 
image pre-processing will be performed depending on the analysis environment 
used. In fact, the implementation of supervised learning starts with finding 
a repository of bioimage dataset that contains the original images and the 
corresponding supervised labels. Once the repository is found, the image data 
is downloaded from the repository, the data is loaded, and it is prepared in 
a format suitable for the analysis environment. These processes are 
time-consuming before analysis.
Also, in most cases of image repositories, the data is not published in a format 
suitable for reading and processing data in R (.Rdata, csv, etc.). They are 
not easy to use for R users.

For mainly performing supervised learning of bioimage data, AHBioImageDbs 
provides list objects of original images and their corresponding supervised 
labels converted into the 4D or 5D arrays.
After downloading the data from AnnotationHub, it can be used for deep learning 
using Keras/Tensorflow [4] and other machine learning without pre-processing.

On the other hand, many image analysis packages are also available on R, but 
there is a lack of standardization in image analysis. The use of common, open 
datasets is one of the essential steps in standardizing and comparing the 
analytical methods. The provision of this image array data through AnnotationHub
is also intended for applications such as (1) comparing models using common data
among R users, and (2) applying predictions to new datasets by transfer learning
and fine-tuning based on these arrays.

# Fetch Bioimage Datasets from AnnotationHub

The `AHBioImageDbs` package provides the metadata for all BioImage 
databases in `r Biocpkg("AnnotationHub")`. 

The `AHBioImageDbs` package provides the metadata for bioimage datasets,
which is preprocessed as array format and saved in
`r Biocpkg("AnnotationHub")`.

First we load/update the `AnnotationHub` resource.

```{r load-lib, message = FALSE}
library(AnnotationHub)
ah <- AnnotationHub()
```

Next we list all AHBioImageDbs entries from `AnnotationHub`.

```{r list-BioImageDbs}
query(ah, "BioImage")
```

We can confirm the metadata in AnnotationHub in Bioconductor S3 bucket
with `mcols()`.

```{r confirm-metadata}
mcols(query(ah, "BioImage"))
```

We can retrieve only the AHBioImageDbs tibble files as follows.

```{r query-mouse}
qr <- query(ah, c("BioImageDbs"))
BioImageDbs_tibble <- qr[[1]]
```

# 5D Arrays from the AnnotationHub

The ordering of the array dimensions is corresponded to the channels_last 
(default) in Keras. The input shape of 5D array is to be batch, spatial_dim1, 
spatial_dim2, spatial_dim3, and channels.

```{r}

```

# 4D Arrays from the AnnotationHub

The ordering of the array dimensions is corresponded to the channels_last 
(default) in Keras. The input shape of 4D array is to be batch, height, width, 
channels.

```{r}

```

# Visualization of gif images from the AnnotationHub

As a test, we also provided gif files of some arrays for visualizations.

You can see the files using `magick::image_read` function.

```{r}
qr <- query(ah, c("BioImageDbs", ".gif"))
(magick::image_read(qr[1]))
```

# Simple Example of execution command in Keras/Tensorflow

First, you select data arrays and label arrays from the list data and assign 
them to variables respectively. These variables are then used as the x and y 
arguments of the Keras fit(<keras.engine.training.Model>) function as a following example.

> data <- 
> labels <- 
> model %>% fit( x = data, y = labels )

# About the imaging dataset and its metadata

For this dataset in AHBioImageDbs , the published open data on each web-sites 
was used as following; 

1) For the cellular microstructures, the cell tracking, electron microscopy-
based imaging data of mouse brain 
(EM_id0001_Brain_CA1_hippocampus_region_5dTensor.Rda) [5-6], Drosophila brain 
(EM_id0002_Drosophila_brain_region_5dTensor.Rda) [7-8], mouse B myeloma cell 
line J558L (EM_id0003_J558L_4dTensor.Rda) [9], and The primary human T cell 
isolated from peripheral blood mononuclear cells 
(EM_id0004_PrHudata_4dTensor.Rda) [9].

2) For the cell tracking, light microscopy-based imaging data of human HeLa 
cells on a flat glass (ex. LM_id0001_DIC_C2DH_HeLa_4dTensor.Rda) [10], human 
glioblastoma-astrocytoma U373 cells on a polyacrylamide substrate (ex. 
LM_id0002_PhC_C2DH_U373_4dTensor.Rda) [10], and GFP-GOWT1 mouse stem cells 
(ex. LM_id0003_Fluo_N2DH_GOWT1_4dTensor.Rda) [11]

The detailed information was described in the metadata file of AHBioImageDbs.

# References

1. Williams, E., Moore, J., Li, S.W. et al. (2018) Publisher Correction: 
Image Data Resource: a bioimage data integration and publication platform. 
Nat Methods 15, 984. https://doi.org/10.1038/s41592-018-0169-x

2. Kobayashi, N., Kume, S., Lenz, K., & Masuya, H. (2018). RIKEN MetaDatabase: 
A Database Platform for Health Care and Life Sciences as a Microcosm of Linked 
Open Data Cloud. International Journal on Semantic Web and Information Systems 
(IJSWIS), 14(1), 140-164. doi:10.4018/IJSWIS.2018010106

3. Kume, S., Masuya, H., Maeda, M., Suga, M., Kataoka, Y., Kobayashi, N. (2017) 
Development of Semantic Web-Based Imaging Database for Biological Morphome. 
In: Wang Z., Turhan AY., Wang K., Zhang X. (eds) Semantic Technology. JIST 2017.
Lecture Notes in Computer Science, vol 10675. Springer, Cham. 
https://doi.org/10.1007/978-3-319-70682-5_19

4. Chollet, François and Allaire, J.J. and others. (2017) R Interface to Keras, 
https://github.com/rstudio/keras

5. Lucchi, A., Li, Y. and Fua, P. (2013.) Learning for Structured Prediction 
Using Approximate Subgradient Descent with Working Sets, 2013 IEEE Conference 
on Computer Vision and Pattern Recognition. doi: 10.1109/CVPR.2013.259

6. Lucchi, A., Smithm K., Achantam R., Knott, G., Fua, P. (2012) 
Supervoxel-based segmentation of mitochondria in em image stacks with learned 
shape features. IEEE Trans Med Imaging. 31(2):474-86. 
doi: 10.1109/TMI.2011.2171705.

7. Cardona, A., Saalfeld, S., Preibisch, S., Schmid, B., Cheng, A., Pulokas, J.,
Tomancak, P., Hartenstein, V. (2010) An Integrated Micro- and Macroarchitectural
Analysis of the Drosophila Brain by Computer-Assisted Serial Section Electron 
Microscopy. PLoS Biol 8(10): e1000502. doi:10.1371/journal.pbio.1000502.

8. Ignacio, A.C., Srinivas, C., Turaga, D.R. et al. (2015) Crowdsourcing the 
creation of image segmentation algorithms for connectomics. Frontiers in 
Neuroanatomy, vol. 9, no. 142.

9. Morath, V., Keuper, M., Rodriguez-Franco, M., et al. (2013) Semi-automatic 
determination of cell surface areas used in systems biology. Frontiers in 
Bioscience, Elite, 5, 533-545. doi:10.2741/e635. 

10. http://celltrackingchallenge.net/2d-datasets/

11. Bártová E, Šustáčková G, Stixová L, Kozubek S, Legartová S, et al. (2011) 
Recruitment of Oct4 Protein to UV-Damaged Chromatin in Embryonic Stem Cells. 
PLOS ONE 6(12): e27281. https://doi.org/10.1371/journal.pone.0027281

# Session information {.unnumbered}
```{r sessionInfo, echo=FALSE}
sessionInfo()
```
